# TransformerLanguageModel
Implementation of a Language Model with Multi Head Attention Blocks. 
Additional decoding capability also implemented in the form of beam search sampling!

Inspired by Andrej Karpathie's "nano-GPT" lecture: https://github.com/karpathy/ng-video-lecture

